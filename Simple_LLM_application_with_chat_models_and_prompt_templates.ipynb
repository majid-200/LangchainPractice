{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "624e0c13-3fba-4f7e-a964-56725ec8ecd7",
   "metadata": {},
   "source": [
    "## Using Ollama as the model provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25eba353-2260-49d2-a9fc-073cad2e7b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34f3bbf4-08ab-4850-a8bc-f11f981ac299",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOllama(\n",
    "    model=\"llama3.1\",\n",
    "    temperature=0,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bd38410-512f-4ec0-85c4-837346005b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ciao!', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2025-07-29T20:12:02.3979596Z', 'done': True, 'done_reason': 'stop', 'total_duration': 5435352600, 'load_duration': 4588792100, 'prompt_eval_count': 24, 'prompt_eval_duration': 382000000, 'eval_count': 4, 'eval_duration': 68000000, 'model_name': 'llama3.1'}, id='run--6097aee1-a940-43d1-ae8e-d1d1c2572aa7-0', usage_metadata={'input_tokens': 24, 'output_tokens': 4, 'total_tokens': 28})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"translate the following from English into Italian\"),\n",
    "    HumanMessage(\"Hi!\")\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64dcff76-d449-4208-a35c-3f879935a366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How are you today? Is there something I can help you with or would you like to chat?', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2025-07-29T20:15:01.4349522Z', 'done': True, 'done_reason': 'stop', 'total_duration': 629785600, 'load_duration': 26679700, 'prompt_eval_count': 11, 'prompt_eval_duration': 81000000, 'eval_count': 23, 'eval_duration': 521000000, 'model_name': 'llama3.1'}, id='run--0428cd86-57b3-41e4-8c88-48750fb9321a-0', usage_metadata={'input_tokens': 11, 'output_tokens': 23, 'total_tokens': 34})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4818afa4-ce68-479e-9790-5ae50d2bd817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How are you today? Is there something I can help you with or would you like to chat?', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2025-07-29T20:15:08.4176285Z', 'done': True, 'done_reason': 'stop', 'total_duration': 649991800, 'load_duration': 18337100, 'prompt_eval_count': 11, 'prompt_eval_duration': 4000000, 'eval_count': 23, 'eval_duration': 625000000, 'model_name': 'llama3.1'}, id='run--92d4ddb8-9096-4d6f-aad7-a0c1188c254b-0', usage_metadata={'input_tokens': 11, 'output_tokens': 23, 'total_tokens': 34})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([{\"role\": \"user\", \"content\": \"Hello\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "669f7366-511d-4c42-aaef-84ca9cf81951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How are you today? Is there something I can help you with or would you like to chat?', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2025-07-29T20:15:10.8604113Z', 'done': True, 'done_reason': 'stop', 'total_duration': 547961100, 'load_duration': 17300800, 'prompt_eval_count': 11, 'prompt_eval_duration': 4000000, 'eval_count': 23, 'eval_duration': 525000000, 'model_name': 'llama3.1'}, id='run--dcec3261-7b10-4166-be6b-e7050ad4c71a-0', usage_metadata={'input_tokens': 11, 'output_tokens': 23, 'total_tokens': 34})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([HumanMessage(\"Hello\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f162dd5e-5439-4172-a826-5538f34c405e",
   "metadata": {},
   "source": [
    "## Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ff263e4-571a-4282-9f54-5ed2fe60e12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C|iao|!||"
     ]
    }
   ],
   "source": [
    "for token in model.stream(messages):\n",
    "    print(token.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f47d0a-798b-4326-90c0-3a61f0cb1b6e",
   "metadata": {},
   "source": [
    "## Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d68fe7d-0d38-4161-beec-4937f6838ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_template = \"Translate the following from English into {language}\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b9d20a0-162d-43ed-9b2b-8d57a01e6afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Translate the following from English into french', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hi!', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = prompt_template.invoke({\"language\": \"french\", \"text\": \"Hi!\"})\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a795a2c-3e20-4d57-ac5a-4574b757017e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour !\n"
     ]
    }
   ],
   "source": [
    "response = model.invoke(prompt)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c465a4d-dff9-4b5c-8b25-944d42570892",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Ollama)",
   "language": "python",
   "name": "ollama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
